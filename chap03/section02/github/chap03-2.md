# chap 03-2 경사 하강법으로 학습하는 방법을 알아봅니다

2021.03.14

<br>

### 01. 그래프로 경사 하강법의 의미를 알아봅니다

```markdown
 * 여러 개의 특성을 가진 데이터를 이용하여 그래프를 그릴 때 알고리즘에 대한 직관을 쉽게 얻고 낮은 차원에서 얻은 직관은 높은 차원으로 확장될 수 있으므로 입력 데이터의 특성 1개를 골라 시각화하는 경우가 많음
```

* 선형 회귀와 경사 하강법의 관계를 이해합시다
  * 선형 회귀의 목표: 입력 데이터(x)와 타깃 데이터(y)를 통해 기울기(a)와 절편(b)을 찾아 산점도 그래프를 잘 표현하는 직선의 방정식을 구하는 것이 목표
  * 회귀 문제를 푸는 알고리즘
    * 경사 하강법(gradient descent): 모델이 데이터를 잘 표현할 수 있도록 기울기(변화율)를 사용하여 모델을 조금씩 조정하는 최적화 알고리즘
    * 정규 방정식(Normal Equation), 결정 트리(Decision Tree), 서포트 벡터 머신(Support Vector Machine)

<br>

### 02. 예측값과 변화율에 대해 알아봅니다

```markdown
* 딥러닝 분야에서 모델 표현법(직선의 방정식): ŷ=wx+b (w=가중치, b=절편, ŷ=예측값)
```

* 예측값이란 무엇일까요?
  * 예측값: 입력과 출력 데이터(x,y)를 통해 규칙(a,b)을 발견하여 만든 모델에 새로운 입력값을 넣어 나온 출력 (모델을 통해 예측한 값)

<br>

### 03. 예측값으로 올바른 모델 찾기

* 훈련 데이터(x,y)에 잘 맞는 w와 b를 찾는 방법
  1. 무작위로 w와 b를 정합니다. (무작위로 모델 만들기)
  2. x에서 샘플 하나를 선택하여  ŷ을 계산합니다. (무작위로 모델 예측하기)
  3.  ŷ과 선택한 샘플의 진짜 y를 비교합니다. (예측한 값과 진짜 정답 비교하기, 틀릴 확률 99%)
  4.  ŷ이 y와 더 가까워지도록 w, b를 조정합니다. (모델 조정하기)
  5. 모든 샘플을 처리할 때까지 다시 2~4 항목을 반복합니다.
* 훈련 데이터에 맞는 w와 b 찾아보기 (예제)
  1. w와 b 초기화하기

     * w와 v를 무작위로 초기화 (예제에서는 간단하게 두 값을 모두 실수 1.0으로 정함)

       ```python
       w = 1.0
       b = 1.0
       ```

  2. 훈련 데이터의 첫 번째 샘플 데이터로  ŷ 얻기

     * 임시로 만든 모델로 훈련 데이터의 첫 번째 샘플 x[0]에 대한 ŷ을 계산하여 y_hat 변수에 저장

       ```python
       y_hat = x[0] * w + b
       print(y_hat)	# 1.0616962065186886
       ```

  3. 타깃과 예측 데이터 비교하기

     * 첫 번째 샘플 x[0]에 대응하는 타깃값 y[0]을 출력하여 y_hat의 값과 비교

       ```python
       print(y[0])	# 151.0
       ```

  4. w 값 조절해 예측값 바꾸기

     * w와 b를 무작위 값으로 정하여 예측 결과가 잘 나오지 않아 w와 b를 좀 더 좋은 방향으로 바꿈

     * w와 b를 조금씩 변경해서 y_hat의 변화량을 관찰하여 y_hat이 y[0]에 가까워질 수 있도록 바꿈

       ```python
       w_inc = w + 0.1		# w를 0.1만큼 증가시키고 y_hat의 변화량 관찰
       y_hat_inc = x[0] * w_inc + b
       print(y_hat_inc)	# 1.0678658271705574
       # w 값을 0.1만큼 증가시킨 다음 값을 다시 예측하여 y_hat_inc에 저장 (y_hat보다 증가)
       ```

  5. w 값 조정한 후 예측값 증가 정도 확인하기

     ```python
     w_rate = (y_hat_inc - y_hat) / (w_inc - w)
     print(w_rate)	# 0.061696206518688734
     # y_hat이 증가한 양을 w가 증가한 양으로 나누어 w가 0.1만큼 증가했을 때 y_hat의 증가량 계산
     ```
  
     

<br>

### 04. 변화율로 가중치 업데이트하기



<br>

### 05. 변화율로 절편 업데이트하기



<br>

### 06. 오차 역전파로 가중치와 절편을 더 적절하게 업데이트합니다

