# chap 06-1 신경망 알고리즘을 벡터화하여 한 번에 전체 샘플을 사용합니다

2021.03.

```markdown
머신러닝에서는 훈련 데이터를 2차원 배열로 표현하는 경우가 많으며 이번에는 행렬 개념을 신경망 알고리즘에 도입해 보겠습니다.
```

<br>

### 01. 벡터화된 연산은 알고리즘의 성능을 올립니다

* 넘파이, 머신러닝, 딥러닝 패키지들은 다차원 배열의 계산인 행렬 연산(벡터화된 연산)을 빠르게 수행할 수 있음
* 벡터화(vectorization)된 연산을 사용하면 알고리즘의 성능을 높일 수 있음
* 배치 경사 하강법으로 성능을 올립니다
  * 확률적 경사 하강법: 기중치를 1번 업데이트할 때 1개의 샘플을 사용하므로 손실 함수의 전역 최솟값을 불안정하게 찾음
  * 배치 경사 하강법: 가중치를 1번 업데이트할 때 전체 샘플을 사용하므로 손실 함수의 전역 최솟값을 안정적으로 찾음
    * 가중치를 1번 업데이트할 때 사용되는 데이터의 개수가 많으므로 계산 비용이 많이 듦

<br>

### 02. 벡터 연산과 행렬 연산을 알아봅니다

```python
신경망에서 자주 사용하는 벡터 연산 중 하나인 점 곱(스칼라 곱)과 행렬 곱셈에 대해 알아봅니다
```

* 점 곱을 알아봅니다 (스칼라 곱)

  * 단일층 신경망에서 z를 구하는 방법 (forpass 메서드)

    ```python
    z = np.sum(x * self.w) + self.b
    ```

  * 넘파이의 원소별 곱셈 기능으로 입력과 가중치의 곱을 x * self.w으로 간단하게 표현할 수 있음

    ```python
    x = [x1, x2, ..., xn]
    w = [w1, w2, ..., wn]
    x * w = [x1*w1, x2*w2, ..., xn*wn]
    ```

  * x와 w는 벡터이며 두 벡터를 곱하여 합을 구하는 계산(np.sum(x*self.w))을 점 곱 또는 스칼라 곱이라고 함

    ![image01]

* 점 곱을 행렬 곱셈으로 표현합니다

  * 점 곱을 행렬 곱셈으로 표현

    ![image02]

  * 점 곱을 행렬 곱셈으로 표현하여 코드 수정

    ```python
    z = np.dot(x, self.w) + self.b
    ```

* 전체 샘플에 대한 가중치 곱의 합을 행렬 곱셈으로 구합니다

  * 전체 훈련 데이터 행렬(X)를 가중치(W)와 곱하는 예

    ![image03]

  * 행렬 곱셈을 통해 만들어지는 결과 행렬의 크기

    ```mathematica
    (m, n) * (n, k) = (m, k)
    ```

  * 행렬 곱셈을 넘파이의 np.dot() 함수로 구현

    ```python
    np.dot(x, w)
    ```

<br>

### 03. SingleLayer 클래스에 배치 경사 하강법 적용하기

1. 사용할 패키지 임포트 (넘파이, 맷플롯립)
2. 위스콘신 유방암 데이터 세트를 훈련, 검증, 테스트 세트로 나누고 데이터 살펴보기
3. 사용할 데이터의 크기 확인
4. 정방향 계산을 행렬 곱셈으로 표현하기
5. 그레이디언트 계산 이해하기
6. forpass(), backprop() 메서드에 배치 경사 하강법 적용하기
7. fit() 메서드 수정하기
8. 나머지 메서드 수정하기
9. 훈련 데이터 표준화 전처리하기
10. 배치 경사 하강법 적용
11. 검증 세트로 성능 측정하고 그래프로 비교하기
12. 가중치의 변화를 그래프로 나타내어 결과의 원인 분석